{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pursuant-phone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "express-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "##1.Schritt einbringen von dem 3. Frame von MOT16-04 \n",
    "\n",
    "img = Image.open(\"TestFrame000003.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "regulation-azerbaijan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           x    y    w    h\n",
      "2       1362  568  103  241\n",
      "1052     372  407   80  239\n",
      "1732     102  549   83  250\n",
      "2782    1732  457   76  212\n",
      "3832    1104  978   78  210\n",
      "...      ...  ...  ...  ...\n",
      "88299    264   71   54  166\n",
      "89349    209   95   41  179\n",
      "90399    914 -107   38  115\n",
      "98591   1217  -14   65  147\n",
      "106177    39  309  115  117\n",
      "\n",
      "[99 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "##2.Schritt einbringen von x, y, w, h aus der gt Datei mit PANDAS\n",
    "\n",
    "    ##gt.txt öffnen\n",
    "open(\"gt.txt\", \"r\")\n",
    "Koordinaten = open(\"gt.txt\", \"r\")\n",
    "\n",
    "    ##gt.txt in PANDAS Tabelle\n",
    "data = pd.read_csv('gt.txt', header = None)\n",
    "data.columns = ['Frame', 'ID', 'x', 'y', 'w', 'h', 'Dies', 'Das', 'Visability']\n",
    "\n",
    "    ##nur Zeilen die mit 3 starten - alle anderen löschen\n",
    "data.drop(data[data.Frame != 3].index, inplace=True)\n",
    "\n",
    "    ##nur x, y, w, h\n",
    "data.drop(['Frame', 'ID', 'Dies', 'Das', 'Visability'], axis=1, inplace=True)\n",
    "print(data)\n",
    "\n",
    "x = data.at[2, 'x']\n",
    "y = data.at[2, 'y']\n",
    "w = data.at[2, 'w']\n",
    "h = data.at[2, 'h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "worst-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "##3.Schritt ausschneiden einer Bounding Box von einem dieser Frames\n",
    "img2 = img.crop((x, y, x+w, y+h))\n",
    "img2.save('TestBoundingBox.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "competent-triple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 598, 256])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##4.Schritt Transformieren und Normalisieren des Bounding-Box Bildes\n",
    "\n",
    "    ##Normalization: image = (image - mean) / std\n",
    "        ##torchvision.transforms.Resize(size, interpolation=2)    size = (h, w)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "trans_img = transform (img2)\n",
    "\n",
    "trans_img.size()\n",
    "trans_img_size = trans_img.unsqueeze(0)\n",
    "trans_img_size.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "roman-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "##5.Schritt ResNet34 Model laden\n",
    "cnn = torchvision.models.resnet50(pretrained=True)\n",
    "cnn = torch.nn.Sequential(*(list(cnn.children())[:-1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "behavioral-breathing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3737, 0.5099, 0.5011,  ..., 0.3255, 0.4519, 0.3247],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##6.Schritt Bounding Box Bild durch das CNN jagen\n",
    "result = cnn(trans_img_size)\n",
    "result.view(2048)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
