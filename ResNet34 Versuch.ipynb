{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-phone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "##1.Schritt einbringen von dem 3. Frame von MOT16-04 \n",
    "\n",
    "img = Image.open(\"TestFrame000003.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dedicated-salvation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-adecdb11ea26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m##Koordinaten in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mKoordinaten2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Koordinaten.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mKoordinaten2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "##2.Schritt einbringen von Koordinaten von einer Results Datei\n",
    "\n",
    "    ##Koordinaten öfnen\n",
    "open(\"Koordinaten.txt\", \"r\")\n",
    "Koordinaten = open(\"Koordinaten.txt\", \"r\")\n",
    "\n",
    "\n",
    "    ##Koordinaten in Numpy\n",
    "Koordinaten2 = np.genfromtxt(\"Koordinaten.txt\", delimiter=\",\")\n",
    "Koordinaten2\n",
    "\n",
    "    ##nur Zeilen dir mit 3 Starten\n",
    "    ##numpy.delete(Koordinaten2, ersteZahlinColumnnicht3, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "    ##alles außer Koordinaten löschen: ..., ..., x, y, w, h, ..., ..., ...\n",
    "    \n",
    "    ##Koordinaten in Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "worst-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "##3.Schritt ausschneiden einer Bounding Box von einem dieser Frames\n",
    "    \n",
    "x=1362\n",
    "y=568\n",
    "w=103\n",
    "h=241\n",
    "    \n",
    "img2 = img.crop((x, y, x+w, y+h))\n",
    "img2.save('TestBoundingBox.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "competent-triple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torchvision.transforms.functional.normalize(tensor: torch.Tensor, mean: List[float], std: List[float], inplace: bool = False) -> torch.Tensor>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##4.Schritt Transformieren und Normalisieren des Bounding-Box Bildes\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "F.normalize\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "roman-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "##5.Schritt ResNet34 Model laden\n",
    "cnn = torchvision.models.resnet34(pretrained=True)\n",
    "cnn = torch.nn.Sequential(*(list(cnn.children())[:-1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "behavioral-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "##6.Schritt Bounding Box Bild durch das CNN jagen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
