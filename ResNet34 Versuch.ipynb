{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pursuant-phone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "express-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "##1.Schritt einbringen von dem 3. Frame von MOT16-04 \n",
    "\n",
    "img = Image.open(\"TestFrame000003.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "regulation-azerbaijan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           x    y    w    h\n",
      "2       1362  568  103  241\n",
      "1052     372  407   80  239\n",
      "1732     102  549   83  250\n",
      "2782    1732  457   76  212\n",
      "3832    1104  978   78  210\n",
      "...      ...  ...  ...  ...\n",
      "88299    264   71   54  166\n",
      "89349    209   95   41  179\n",
      "90399    914 -107   38  115\n",
      "98591   1217  -14   65  147\n",
      "106177    39  309  115  117\n",
      "\n",
      "[99 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "##2.Schritt einbringen von x, y, w, h aus der gt Datei mit PANDAS\n",
    "\n",
    "    ##gt.txt öffnen\n",
    "open(\"gt.txt\", \"r\")\n",
    "Koordinaten = open(\"gt.txt\", \"r\")\n",
    "\n",
    "    ##gt.txt in PANDAS Tabelle\n",
    "data = pd.read_csv('gt.txt', header = None)\n",
    "data.columns = ['Frame', 'ID', 'x', 'y', 'w', 'h', 'Dies', 'Das', 'Visability']\n",
    "\n",
    "    ##nur Zeilen die mit 3 starten - alle anderen löschen\n",
    "data.drop(data[data.Frame != 3].index, inplace=True)\n",
    "\n",
    "    ##nur x, y, w, h\n",
    "data.drop(['Frame', 'ID', 'Dies', 'Das', 'Visability'], axis=1, inplace=True)\n",
    "print(data)\n",
    "\n",
    "x = data.at[2, 'x']\n",
    "y = data.at[2, 'y']\n",
    "w = data.at[2, 'w']\n",
    "h = data.at[2, 'h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "worst-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "##3.Schritt ausschneiden einer Bounding Box von einem dieser Frames\n",
    "img2 = img.crop((x, y, x+w, y+h))\n",
    "img2.save('TestBoundingBox.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "competent-triple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 598, 256])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##4.Schritt Transformieren und Normalisieren des Bounding-Box Bildes\n",
    "\n",
    "    ##Normalization: image = (image - mean) / std\n",
    "        ##torchvision.transforms.Resize(size, interpolation=2)    size = (h, w)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "trans_img = transform (img2)\n",
    "\n",
    "trans_img.size()\n",
    "trans_img_size = trans_img.unsqueeze(0)\n",
    "trans_img_size.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "roman-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "##5.Schritt ResNet34 Model laden\n",
    "cnn = torchvision.models.resnet34(pretrained=True)\n",
    "cnn = torch.nn.Sequential(*(list(cnn.children())[:-1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "behavioral-breathing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8707, 0.8550, 1.0356, 0.9202, 0.8550, 1.0271, 1.0008, 0.8715, 0.9966,\n",
       "        0.9982, 0.8885, 0.8526, 0.9885, 0.8443, 0.8160, 1.1151, 0.9773, 0.9675,\n",
       "        0.9039, 0.8446, 1.3552, 0.8911, 1.0123, 0.9089, 0.9153, 0.9438, 0.9299,\n",
       "        0.9428, 0.9977, 1.0652, 1.0114, 0.9382, 0.8584, 0.8747, 0.8892, 1.0681,\n",
       "        0.9393, 0.8797, 0.9721, 0.8740, 0.8887, 0.9539, 0.9548, 0.9862, 0.8565,\n",
       "        0.9653, 0.9207, 1.0210, 0.9118, 0.9027, 0.8447, 1.2383, 0.8582, 0.9673,\n",
       "        0.8983, 0.9060, 0.8572, 0.7836, 0.9808, 0.9536, 0.9295, 1.0631, 0.9304,\n",
       "        0.9447, 0.9278, 0.7992, 0.9094, 0.9617, 0.8389, 0.9482, 1.0417, 0.9746,\n",
       "        0.9211, 0.9276, 0.9321, 1.2293, 0.8616, 0.9883, 1.5001, 0.9103, 0.9789,\n",
       "        1.0419, 0.9160, 0.7732, 0.9130, 1.0819, 0.9976, 0.9110, 0.9224, 0.8120,\n",
       "        1.3816, 0.8510, 0.9796, 0.9269, 0.9035, 1.0673, 1.0364, 1.0012, 0.9736,\n",
       "        0.9298, 0.8890, 0.9535, 0.8620, 0.8529, 0.8957, 0.8433, 0.9875, 0.9692,\n",
       "        0.9150, 0.8689, 1.0480, 0.9467, 1.0020, 0.8986, 0.9003, 0.9422, 0.9660,\n",
       "        0.9652, 1.1092, 0.9761, 0.9315, 0.9377, 0.9563, 0.9004, 0.8663, 1.0021,\n",
       "        0.8815, 1.0996, 0.9810, 0.9362, 0.8577, 0.9552, 0.9583, 1.0045, 0.9253,\n",
       "        0.8850, 1.1119, 0.9736, 0.9821, 0.8346, 1.0120, 1.0963, 0.9447, 0.9625,\n",
       "        0.9880, 0.9612, 1.1919, 0.9466, 1.0340, 0.8589, 1.0058, 0.9217, 0.8785,\n",
       "        1.1182, 1.0075, 1.0133, 0.9829, 1.0536, 1.1262, 0.8900, 1.1019, 0.9585,\n",
       "        0.9118, 0.8303, 1.4300, 0.8621, 1.0653, 1.0275, 0.9328, 0.9248, 0.8818,\n",
       "        0.9081, 1.0046, 0.9394, 0.9955, 0.9917, 0.9727, 0.8727, 0.9327, 0.8969,\n",
       "        0.8936, 0.8455, 0.9235, 0.9415, 0.9766, 0.9120, 0.8883, 0.8739, 0.8818,\n",
       "        0.9725, 1.0240, 0.9294, 0.8960, 0.9499, 0.8887, 0.9213, 0.8690, 0.8878,\n",
       "        0.9864, 0.9487, 0.9096, 0.9290, 0.8904, 0.8813, 0.9062, 1.1685, 1.0380,\n",
       "        0.9490, 0.9740, 0.9598, 0.9301, 0.8438, 0.8917, 0.9882, 0.8766, 0.9206,\n",
       "        0.8874, 1.0524, 0.9403, 0.9360, 0.9930, 1.1294, 0.9071, 0.9155, 1.0122,\n",
       "        0.9363, 0.9214, 0.9799, 0.9981, 0.9621, 0.9168, 0.9078, 0.7997, 1.0275,\n",
       "        0.9725, 0.9829, 0.9745, 0.8814, 0.9047, 0.8771, 0.9927, 1.0144, 1.0474,\n",
       "        0.8696, 0.8751, 0.8689, 0.8580, 0.8945, 0.8570, 0.9522, 0.9920, 0.8949,\n",
       "        0.9807, 0.9876, 0.9131, 1.1000, 1.0074, 0.9172, 0.9870, 0.9223, 1.0025,\n",
       "        0.8370, 0.8689, 0.9924, 0.9779, 1.1347, 0.9635, 0.9936, 0.9808, 0.9662,\n",
       "        0.9147, 1.1816, 0.9446, 1.2513, 0.9127, 0.9540, 0.9217, 0.9662, 1.0287,\n",
       "        0.8574, 0.9674, 0.9191, 0.8747, 0.8959, 1.2137, 1.0049, 1.2104, 0.8321,\n",
       "        0.8801, 0.8900, 0.8760, 0.8009, 1.2843, 0.8203, 0.9609, 1.1811, 0.9772,\n",
       "        0.9880, 1.0923, 0.9462, 0.8906, 1.0130, 0.9154, 0.9109, 0.9470, 0.9035,\n",
       "        0.9313, 0.9281, 0.9813, 0.9570, 0.8882, 0.9949, 0.8989, 0.9796, 0.9813,\n",
       "        0.9846, 1.0329, 0.9139, 0.9268, 0.9241, 1.1231, 0.8763, 0.9676, 1.1238,\n",
       "        0.9021, 0.8408, 0.9873, 0.9006, 0.9342, 1.2166, 1.2184, 0.9769, 0.9890,\n",
       "        0.9166, 0.9054, 0.9418, 0.9461, 0.8165, 1.0117, 0.9366, 0.9538, 0.9249,\n",
       "        0.8657, 0.8592, 0.8931, 0.8721, 1.0014, 1.0729, 1.2012, 0.8603, 0.9651,\n",
       "        1.0128, 1.0362, 0.8311, 0.9167, 0.8778, 0.9087, 0.9419, 0.9416, 0.8396,\n",
       "        1.0526, 1.1063, 0.8300, 0.8674, 0.9226, 0.9303, 0.9193, 0.9196, 0.9101,\n",
       "        0.9550, 0.9170, 0.9809, 0.9267, 0.8224, 0.8480, 0.8688, 0.8419, 0.9433,\n",
       "        0.8508, 1.0465, 0.8751, 0.8187, 0.9089, 0.8868, 1.0770, 0.9492, 0.8555,\n",
       "        0.9118, 0.9270, 0.9604, 0.8742, 0.9397, 1.0684, 0.8845, 0.9130, 0.9249,\n",
       "        0.8447, 0.9421, 1.5580, 0.9008, 1.0388, 0.8628, 0.9073, 0.9963, 0.9123,\n",
       "        0.9248, 1.0126, 0.9032, 0.7585, 0.9101, 0.8803, 1.0402, 0.8863, 0.8819,\n",
       "        0.9779, 0.9638, 0.8801, 1.0509, 0.9959, 0.9863, 0.8452, 1.0956, 0.9830,\n",
       "        0.9379, 0.9219, 0.9977, 0.8574, 0.8851, 0.8071, 1.2262, 0.8409, 0.8798,\n",
       "        0.9364, 0.8873, 0.9317, 0.7686, 0.9995, 1.0090, 0.9851, 0.9050, 1.0032,\n",
       "        0.8500, 0.9409, 1.0011, 0.9967, 0.9473, 0.8921, 0.9234, 1.0761, 0.9144,\n",
       "        1.0459, 0.9088, 0.8920, 0.8941, 0.9629, 0.9455, 0.8981, 0.8860, 0.9000,\n",
       "        0.9503, 1.0888, 1.0927, 0.8958, 0.9199, 0.9268, 0.9066, 1.0218, 0.7979,\n",
       "        1.0068, 1.1470, 0.9066, 0.9284, 0.8805, 0.8665, 0.9450, 0.8932, 0.9595,\n",
       "        1.0695, 0.9099, 1.0515, 0.9946, 0.9296, 0.8266, 1.3024, 0.9705, 1.0493,\n",
       "        1.0177, 0.8464, 1.2003, 1.0434, 0.9555, 1.0084, 1.0215, 1.0313, 1.1285,\n",
       "        1.0305, 0.9468, 0.8884, 0.8948, 1.0405, 0.9109, 0.9748, 0.8623, 0.9509,\n",
       "        0.8478, 0.9276, 0.8671, 0.8421, 1.0190, 0.9567, 0.8370, 0.9662],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##6.Schritt Bounding Box Bild durch das CNN jagen\n",
    "result = cnn(trans_img_size)\n",
    "result.view(512)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
