{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "pursuant-phone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision import models\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "express-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "##1.Schritt einbringen von dem 3. Frame von MOT16-04 \n",
    "\n",
    "img = Image.open(\"TestFrame000003.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "dedicated-salvation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##2.Schritt einbringen von Koordinaten von einer Results Datei\n",
    "\n",
    "open(\"Koordinaten.txt\", \"r\")\n",
    "Koordinaten = open(\"Koordinaten.txt\", \"r\")\n",
    "\n",
    "    ##results = np.loadtxt(Koordinaten, delimiter=',')\n",
    "\n",
    "    ##nur Zeilen dir mit 3 Starten\n",
    "\n",
    "    ##alles außer Koordinaten löschen: ..., ..., x, y, w, h, ..., ..., ...\n",
    "    \n",
    "    \n",
    "    ##Koordinaten in Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "worst-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "##3.Schritt ausschneiden einer Bounding Box von einem dieser Frames\n",
    "    \n",
    "x=1362\n",
    "y=568\n",
    "w=103\n",
    "h=241\n",
    "    \n",
    "img2 = img.crop((x, y, x+w, y+h))\n",
    "img2.save('TestBoundingBox.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "competent-triple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torchvision.transforms.functional.normalize(tensor: torch.Tensor, mean: List[float], std: List[float], inplace: bool = False) -> torch.Tensor>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##4.Schritt Transformieren und Normalisieren des Bounding-Box Bildes\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "F.normalize\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "roman-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "##5.Schritt ResNet34 Model laden\n",
    "cnn = torchvision.models.resnet34(pretrained=True)\n",
    "cnn = torch.nn.Sequential(*(list(cnn.children())[:-1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "behavioral-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "##6.Schritt Bounding Box Bild durch das CNN jagen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
